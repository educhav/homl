{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 16:15:03.486337: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.1 when it was built against 1.14.0, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Nadam Optimization and Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train, y_train = data[0]\n",
    "X_test, y_test = data[1]\n",
    "\n",
    "X_val = X_train[40000:]\n",
    "X_train = X_train[:40000]\n",
    "\n",
    "y_val = y_train[40000:]\n",
    "y_train = y_train[:40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 12s 5ms/step - loss: 11.0068 - accuracy: 0.1193 - val_loss: 3.6182 - val_accuracy: 0.1367\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.9597 - accuracy: 0.1478 - val_loss: 2.4955 - val_accuracy: 0.1696\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3614 - accuracy: 0.1816 - val_loss: 2.2501 - val_accuracy: 0.1931\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.1823 - accuracy: 0.2123 - val_loss: 2.1385 - val_accuracy: 0.2283\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.0871 - accuracy: 0.2391 - val_loss: 2.0501 - val_accuracy: 0.2485\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.0157 - accuracy: 0.2633 - val_loss: 1.9966 - val_accuracy: 0.2737\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.9588 - accuracy: 0.2835 - val_loss: 1.9671 - val_accuracy: 0.2833\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.9118 - accuracy: 0.2974 - val_loss: 1.9418 - val_accuracy: 0.2911\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8707 - accuracy: 0.3144 - val_loss: 1.8821 - val_accuracy: 0.3111\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8303 - accuracy: 0.3299 - val_loss: 1.8610 - val_accuracy: 0.3194\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.8610 - accuracy: 0.3194\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 12s 5ms/step - loss: 8.0071 - accuracy: 0.1498 - val_loss: 2.3904 - val_accuracy: 0.1801\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.2379 - accuracy: 0.2079 - val_loss: 2.1569 - val_accuracy: 0.2265\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.0712 - accuracy: 0.2476 - val_loss: 2.0280 - val_accuracy: 0.2635\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.9912 - accuracy: 0.2705 - val_loss: 1.9804 - val_accuracy: 0.2743\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.9264 - accuracy: 0.2926 - val_loss: 1.9069 - val_accuracy: 0.3040\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8744 - accuracy: 0.3144 - val_loss: 1.8538 - val_accuracy: 0.3236\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8294 - accuracy: 0.3332 - val_loss: 1.8174 - val_accuracy: 0.3386\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7846 - accuracy: 0.3492 - val_loss: 1.8744 - val_accuracy: 0.3272\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7474 - accuracy: 0.3647 - val_loss: 1.7734 - val_accuracy: 0.3611\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.7126 - accuracy: 0.3780 - val_loss: 1.7546 - val_accuracy: 0.3636\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.7546 - accuracy: 0.3636\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 12s 5ms/step - loss: 4.0678 - accuracy: 0.1741 - val_loss: 2.1950 - val_accuracy: 0.2307\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.0898 - accuracy: 0.2460 - val_loss: 2.0608 - val_accuracy: 0.2497\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.9608 - accuracy: 0.2889 - val_loss: 1.9262 - val_accuracy: 0.3005\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.8849 - accuracy: 0.3180 - val_loss: 1.8789 - val_accuracy: 0.3160\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.8263 - accuracy: 0.3383 - val_loss: 1.8395 - val_accuracy: 0.3371\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7754 - accuracy: 0.3552 - val_loss: 1.7871 - val_accuracy: 0.3654\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7324 - accuracy: 0.3754 - val_loss: 1.8305 - val_accuracy: 0.3381\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6966 - accuracy: 0.3865 - val_loss: 1.7229 - val_accuracy: 0.3797\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6640 - accuracy: 0.3986 - val_loss: 1.7090 - val_accuracy: 0.3879\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6340 - accuracy: 0.4104 - val_loss: 1.6835 - val_accuracy: 0.4010\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.6835 - accuracy: 0.4010\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 12s 5ms/step - loss: 4.2714 - accuracy: 0.1757 - val_loss: 2.1149 - val_accuracy: 0.2381\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.0178 - accuracy: 0.2613 - val_loss: 1.9609 - val_accuracy: 0.2906\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.9122 - accuracy: 0.3020 - val_loss: 1.8852 - val_accuracy: 0.3054\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8407 - accuracy: 0.3284 - val_loss: 1.7959 - val_accuracy: 0.3550\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7893 - accuracy: 0.3501 - val_loss: 1.8381 - val_accuracy: 0.3302\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7415 - accuracy: 0.3716 - val_loss: 1.7609 - val_accuracy: 0.3677\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7014 - accuracy: 0.3869 - val_loss: 1.7055 - val_accuracy: 0.3894\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6672 - accuracy: 0.3968 - val_loss: 1.6860 - val_accuracy: 0.3967\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6420 - accuracy: 0.4076 - val_loss: 1.6832 - val_accuracy: 0.4034\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6144 - accuracy: 0.4175 - val_loss: 1.6445 - val_accuracy: 0.4097\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.6445 - accuracy: 0.4097\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 12s 5ms/step - loss: 3.4786 - accuracy: 0.1987 - val_loss: 2.0663 - val_accuracy: 0.2247\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.9764 - accuracy: 0.2705 - val_loss: 1.9181 - val_accuracy: 0.2967\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8886 - accuracy: 0.3099 - val_loss: 1.8418 - val_accuracy: 0.3260\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.8252 - accuracy: 0.3355 - val_loss: 1.8125 - val_accuracy: 0.3439\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7791 - accuracy: 0.3557 - val_loss: 1.7884 - val_accuracy: 0.3553\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7468 - accuracy: 0.3693 - val_loss: 1.7534 - val_accuracy: 0.3681\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7113 - accuracy: 0.3838 - val_loss: 1.7508 - val_accuracy: 0.3668\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6783 - accuracy: 0.3919 - val_loss: 1.6889 - val_accuracy: 0.3950\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6479 - accuracy: 0.4077 - val_loss: 1.6442 - val_accuracy: 0.4095\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6238 - accuracy: 0.4150 - val_loss: 1.6847 - val_accuracy: 0.3940\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.6847 - accuracy: 0.3940\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 12s 5ms/step - loss: 3.3071 - accuracy: 0.2070 - val_loss: 2.0549 - val_accuracy: 0.2301\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.9387 - accuracy: 0.2782 - val_loss: 1.9207 - val_accuracy: 0.2891\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8743 - accuracy: 0.3070 - val_loss: 1.8262 - val_accuracy: 0.3361\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8378 - accuracy: 0.3280 - val_loss: 1.8273 - val_accuracy: 0.3203\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8078 - accuracy: 0.3357 - val_loss: 1.7704 - val_accuracy: 0.3519\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7731 - accuracy: 0.3498 - val_loss: 1.8012 - val_accuracy: 0.3508\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7454 - accuracy: 0.3591 - val_loss: 1.7392 - val_accuracy: 0.3638\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7162 - accuracy: 0.3731 - val_loss: 1.7374 - val_accuracy: 0.3702\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.6863 - accuracy: 0.3881 - val_loss: 1.7357 - val_accuracy: 0.3724\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6542 - accuracy: 0.3984 - val_loss: 1.7065 - val_accuracy: 0.3783\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.7065 - accuracy: 0.3783\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 12s 5ms/step - loss: 3.9585 - accuracy: 0.2202 - val_loss: 1.9395 - val_accuracy: 0.2918\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.9372 - accuracy: 0.2826 - val_loss: 1.8832 - val_accuracy: 0.3143\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.8705 - accuracy: 0.3124 - val_loss: 1.8986 - val_accuracy: 0.2924\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.8346 - accuracy: 0.3252 - val_loss: 1.8874 - val_accuracy: 0.3150\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.8071 - accuracy: 0.3371 - val_loss: 1.7992 - val_accuracy: 0.3441\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7826 - accuracy: 0.3510 - val_loss: 1.7704 - val_accuracy: 0.3625\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7586 - accuracy: 0.3614 - val_loss: 1.8010 - val_accuracy: 0.3624\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7510 - accuracy: 0.3643 - val_loss: 1.7676 - val_accuracy: 0.3549\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.9865 - accuracy: 0.2832 - val_loss: 1.9473 - val_accuracy: 0.2547\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8818 - accuracy: 0.2939 - val_loss: 1.8839 - val_accuracy: 0.3073\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.8839 - accuracy: 0.3073\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 12s 5ms/step - loss: 7.2644 - accuracy: 0.2208 - val_loss: 1.9298 - val_accuracy: 0.2859\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.9300 - accuracy: 0.2867 - val_loss: 1.9241 - val_accuracy: 0.2965\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8944 - accuracy: 0.3029 - val_loss: 1.8685 - val_accuracy: 0.3182\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8793 - accuracy: 0.3074 - val_loss: 1.8643 - val_accuracy: 0.3235\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8630 - accuracy: 0.3194 - val_loss: 1.9352 - val_accuracy: 0.3079\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8731 - accuracy: 0.3152 - val_loss: 1.8511 - val_accuracy: 0.3225\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 119.3294 - accuracy: 0.1635 - val_loss: 2.2265 - val_accuracy: 0.1529\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 7.4719 - accuracy: 0.1407 - val_loss: 2.3072 - val_accuracy: 0.0980\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3093 - accuracy: 0.0981 - val_loss: 2.3106 - val_accuracy: 0.1022\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3119 - accuracy: 0.0990 - val_loss: 2.3141 - val_accuracy: 0.0952\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.3141 - accuracy: 0.0952\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 12s 5ms/step - loss: 6.6412 - accuracy: 0.2138 - val_loss: 2.0074 - val_accuracy: 0.2398\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.9422 - accuracy: 0.2829 - val_loss: 1.9424 - val_accuracy: 0.2754\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.9064 - accuracy: 0.3002 - val_loss: 1.9071 - val_accuracy: 0.3047\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8981 - accuracy: 0.3058 - val_loss: 2.0056 - val_accuracy: 0.2837\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 35.0322 - accuracy: 0.1826 - val_loss: 2.3090 - val_accuracy: 0.0977\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3243 - accuracy: 0.1010 - val_loss: 2.3075 - val_accuracy: 0.1025\n",
      "Epoch 7/10\n",
      " 161/1250 [==>...........................] - ETA: 5s - loss: 2.3254 - accuracy: 0.0986"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 25\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m rate \u001b[39min\u001b[39;00m rates:\n\u001b[1;32m     21\u001b[0m     model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mNadam(learning_rate\u001b[39m=\u001b[39mrate, beta_1\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m, beta_2\u001b[39m=\u001b[39m\u001b[39m0.999\u001b[39m), \n\u001b[1;32m     22\u001b[0m                 loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m                 metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m],)\n\u001b[0;32m---> 25\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val), callbacks\u001b[39m=\u001b[39;49m[tensorboard, early_stopping])\n\u001b[1;32m     26\u001b[0m     losses\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mevaluate(X_val, y_val))\n\u001b[1;32m     27\u001b[0m     run_index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[32,32,3]),\n",
    "])\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_normal\"))\n",
    "\n",
    "run_index = 1\n",
    "log_dir = os.path.join(os.curdir, \"logs\", \"run_\" + str(run_index))\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir)\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=10)\n",
    "rates = [1e-5, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3, 3e-3, 5e-3]\n",
    "losses = []\n",
    "\n",
    "untrained_model = keras.models.clone_model(model)\n",
    "\n",
    "for rate in rates:\n",
    "    model.compile(optimizer=keras.optimizers.Nadam(learning_rate=rate, beta_1=0.9, beta_2=0.999), \n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=[\"accuracy\"],)\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=[tensorboard, early_stopping])\n",
    "    losses.append(model.evaluate(X_val, y_val))\n",
    "    run_index += 1\n",
    "    log_dir = os.path.join(os.curdir, \"logs\", \"run_\" + str(run_index))\n",
    "    tensorboard = keras.callbacks.TensorBoard(log_dir)\n",
    "    model = keras.models.clone_model(untrained_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def find_optimal_lr(model: keras.Model, X_train, y_train, X_val, y_val, epochs=10, orders=5):\n",
    "    bases = [1,3,5]\n",
    "    rates = []\n",
    "    for order in range(orders, 0, -1):\n",
    "        for base in bases:\n",
    "            rates.append(base/10**order)\n",
    "    print(rates)\n",
    "    untrained_model = keras.models.clone_model(model)\n",
    "    accuracies = []\n",
    "    for rate in rates:\n",
    "        model.compile(optimizer=keras.optimizers.Nadam(learning_rate=rate), \n",
    "                      loss=\"sparse_categorical_crossentropy\", \n",
    "                      metrics=[\"accuracy\"])\n",
    "        model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val))\n",
    "        accuracy = model.evaluate(X_val, y_val)[1]\n",
    "        accuracies.append(accuracy)\n",
    "        model = keras.models.clone_model(untrained_model)\n",
    "    \n",
    "    return rates[np.argmax(accuracies)]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31940001 0.36359999 0.40099999 0.40970001 0.39399999 0.37830001\n",
      " 0.3073     0.0952    ]\n",
      "0.0001\n",
      "3\n",
      "Epoch 1/300\n",
      "1250/1250 [==============================] - 12s 5ms/step - loss: 3.8212 - accuracy: 0.1801 - val_loss: 2.0699 - val_accuracy: 0.2497\n",
      "Epoch 2/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.0058 - accuracy: 0.2637 - val_loss: 2.0026 - val_accuracy: 0.2820\n",
      "Epoch 3/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.9133 - accuracy: 0.3049 - val_loss: 1.9354 - val_accuracy: 0.3004\n",
      "Epoch 4/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.8504 - accuracy: 0.3272 - val_loss: 1.8308 - val_accuracy: 0.3394\n",
      "Epoch 5/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8009 - accuracy: 0.3439 - val_loss: 1.7849 - val_accuracy: 0.3566\n",
      "Epoch 6/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7562 - accuracy: 0.3619 - val_loss: 1.7752 - val_accuracy: 0.3586\n",
      "Epoch 7/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7181 - accuracy: 0.3760 - val_loss: 1.7013 - val_accuracy: 0.3921\n",
      "Epoch 8/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6767 - accuracy: 0.3929 - val_loss: 1.6729 - val_accuracy: 0.4009\n",
      "Epoch 9/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6449 - accuracy: 0.4056 - val_loss: 1.7223 - val_accuracy: 0.3760\n",
      "Epoch 10/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6178 - accuracy: 0.4175 - val_loss: 1.6809 - val_accuracy: 0.3958\n",
      "Epoch 11/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5897 - accuracy: 0.4270 - val_loss: 1.6291 - val_accuracy: 0.4177\n",
      "Epoch 12/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5723 - accuracy: 0.4315 - val_loss: 1.6456 - val_accuracy: 0.4181\n",
      "Epoch 13/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5498 - accuracy: 0.4397 - val_loss: 1.6287 - val_accuracy: 0.4168\n",
      "Epoch 14/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5270 - accuracy: 0.4500 - val_loss: 1.5884 - val_accuracy: 0.4348\n",
      "Epoch 15/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5091 - accuracy: 0.4583 - val_loss: 1.5647 - val_accuracy: 0.4466\n",
      "Epoch 16/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4916 - accuracy: 0.4639 - val_loss: 1.5935 - val_accuracy: 0.4322\n",
      "Epoch 17/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4745 - accuracy: 0.4699 - val_loss: 1.5764 - val_accuracy: 0.4392\n",
      "Epoch 18/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4630 - accuracy: 0.4726 - val_loss: 1.5836 - val_accuracy: 0.4389\n",
      "Epoch 19/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4460 - accuracy: 0.4785 - val_loss: 1.5407 - val_accuracy: 0.4536\n",
      "Epoch 20/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.4338 - accuracy: 0.4854 - val_loss: 1.5693 - val_accuracy: 0.4506\n",
      "Epoch 21/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.4217 - accuracy: 0.4882 - val_loss: 1.5638 - val_accuracy: 0.4445\n",
      "Epoch 22/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.4132 - accuracy: 0.4922 - val_loss: 1.5583 - val_accuracy: 0.4478\n",
      "Epoch 23/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.3956 - accuracy: 0.5044 - val_loss: 1.5142 - val_accuracy: 0.4631\n",
      "Epoch 24/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.3829 - accuracy: 0.5040 - val_loss: 1.5734 - val_accuracy: 0.4452\n",
      "Epoch 25/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.3746 - accuracy: 0.5054 - val_loss: 1.5524 - val_accuracy: 0.4506\n",
      "Epoch 26/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3622 - accuracy: 0.5108 - val_loss: 1.5504 - val_accuracy: 0.4532\n",
      "Epoch 27/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3495 - accuracy: 0.5157 - val_loss: 1.5230 - val_accuracy: 0.4604\n",
      "Epoch 28/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3437 - accuracy: 0.5171 - val_loss: 1.5372 - val_accuracy: 0.4552\n",
      "Epoch 29/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3299 - accuracy: 0.5212 - val_loss: 1.5199 - val_accuracy: 0.4636\n",
      "Epoch 30/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3163 - accuracy: 0.5279 - val_loss: 1.5452 - val_accuracy: 0.4605\n",
      "Epoch 31/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3080 - accuracy: 0.5309 - val_loss: 1.5470 - val_accuracy: 0.4534\n",
      "Epoch 32/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.2969 - accuracy: 0.5358 - val_loss: 1.5536 - val_accuracy: 0.4614\n",
      "Epoch 33/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.2907 - accuracy: 0.5372 - val_loss: 1.5346 - val_accuracy: 0.4655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc291a20f50>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "best_index = np.argmax(np.array(losses)[:, 1])\n",
    "best_rate = rates[best_index]\n",
    "\n",
    "model = keras.models.clone_model(untrained_model)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.Nadam(learning_rate=best_rate),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=300, validation_data=(X_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 1.5206 - accuracy: 0.4735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5205923318862915, 0.47350001335144043]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-05, 3e-05, 5e-05, 0.0001, 0.0003, 0.0005, 0.001, 0.003, 0.005, 0.01, 0.03, 0.05, 0.1, 0.3, 0.5]\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 25s 11ms/step - loss: 2.6528 - accuracy: 0.1438 - val_loss: 2.3980 - val_accuracy: 0.1820\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.3124 - accuracy: 0.1931 - val_loss: 2.2072 - val_accuracy: 0.2236\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.1703 - accuracy: 0.2253 - val_loss: 2.1026 - val_accuracy: 0.2492\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.0769 - accuracy: 0.2555 - val_loss: 2.0262 - val_accuracy: 0.2701\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.0114 - accuracy: 0.2752 - val_loss: 1.9667 - val_accuracy: 0.2989\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9642 - accuracy: 0.2939 - val_loss: 1.9263 - val_accuracy: 0.3120\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9249 - accuracy: 0.3074 - val_loss: 1.8816 - val_accuracy: 0.3302\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.8914 - accuracy: 0.3198 - val_loss: 1.8574 - val_accuracy: 0.3364\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.8635 - accuracy: 0.3322 - val_loss: 1.8268 - val_accuracy: 0.3479\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.8351 - accuracy: 0.3401 - val_loss: 1.7967 - val_accuracy: 0.3586\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7967 - accuracy: 0.3586\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 26s 11ms/step - loss: 2.3468 - accuracy: 0.1882 - val_loss: 2.0676 - val_accuracy: 0.2581\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.0100 - accuracy: 0.2767 - val_loss: 1.9079 - val_accuracy: 0.3198\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9075 - accuracy: 0.3114 - val_loss: 1.8127 - val_accuracy: 0.3520\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.8347 - accuracy: 0.3401 - val_loss: 1.7456 - val_accuracy: 0.3769\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7809 - accuracy: 0.3604 - val_loss: 1.7078 - val_accuracy: 0.3912\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7393 - accuracy: 0.3744 - val_loss: 1.6704 - val_accuracy: 0.4040\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7058 - accuracy: 0.3886 - val_loss: 1.6304 - val_accuracy: 0.4215\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6717 - accuracy: 0.4021 - val_loss: 1.6065 - val_accuracy: 0.4278\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6383 - accuracy: 0.4146 - val_loss: 1.5802 - val_accuracy: 0.4423\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6140 - accuracy: 0.4239 - val_loss: 1.5651 - val_accuracy: 0.4469\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5651 - accuracy: 0.4469\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 25s 11ms/step - loss: 2.2732 - accuracy: 0.2089 - val_loss: 1.9901 - val_accuracy: 0.2855\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9465 - accuracy: 0.2978 - val_loss: 1.8309 - val_accuracy: 0.3448\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.8437 - accuracy: 0.3398 - val_loss: 1.7500 - val_accuracy: 0.3731\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7781 - accuracy: 0.3638 - val_loss: 1.6969 - val_accuracy: 0.3966\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7211 - accuracy: 0.3855 - val_loss: 1.6409 - val_accuracy: 0.4200\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6736 - accuracy: 0.4009 - val_loss: 1.6165 - val_accuracy: 0.4212\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6324 - accuracy: 0.4195 - val_loss: 1.5756 - val_accuracy: 0.4347\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6022 - accuracy: 0.4295 - val_loss: 1.5518 - val_accuracy: 0.4482\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5732 - accuracy: 0.4404 - val_loss: 1.5298 - val_accuracy: 0.4560\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5505 - accuracy: 0.4500 - val_loss: 1.5083 - val_accuracy: 0.4610\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5083 - accuracy: 0.4610\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 25s 11ms/step - loss: 2.1637 - accuracy: 0.2320 - val_loss: 1.8715 - val_accuracy: 0.3320\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.8547 - accuracy: 0.3333 - val_loss: 1.7354 - val_accuracy: 0.3798\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7595 - accuracy: 0.3711 - val_loss: 1.6654 - val_accuracy: 0.3986\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6949 - accuracy: 0.3943 - val_loss: 1.6175 - val_accuracy: 0.4198\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6446 - accuracy: 0.4103 - val_loss: 1.5712 - val_accuracy: 0.4407\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5959 - accuracy: 0.4314 - val_loss: 1.5389 - val_accuracy: 0.4524\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5581 - accuracy: 0.4433 - val_loss: 1.5067 - val_accuracy: 0.4687\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5287 - accuracy: 0.4554 - val_loss: 1.4878 - val_accuracy: 0.4668\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4954 - accuracy: 0.4681 - val_loss: 1.4800 - val_accuracy: 0.4758\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4688 - accuracy: 0.4788 - val_loss: 1.4418 - val_accuracy: 0.4869\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4418 - accuracy: 0.4869\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 26s 11ms/step - loss: 1.9741 - accuracy: 0.2980 - val_loss: 1.7582 - val_accuracy: 0.3770\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7549 - accuracy: 0.3737 - val_loss: 1.6457 - val_accuracy: 0.4114\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6710 - accuracy: 0.4047 - val_loss: 1.5832 - val_accuracy: 0.4355\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6146 - accuracy: 0.4257 - val_loss: 1.5382 - val_accuracy: 0.4535\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5605 - accuracy: 0.4421 - val_loss: 1.5143 - val_accuracy: 0.4546\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5260 - accuracy: 0.4584 - val_loss: 1.4726 - val_accuracy: 0.4699\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4842 - accuracy: 0.4719 - val_loss: 1.4549 - val_accuracy: 0.4850\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4544 - accuracy: 0.4854 - val_loss: 1.4289 - val_accuracy: 0.4928\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4224 - accuracy: 0.4972 - val_loss: 1.4113 - val_accuracy: 0.5021\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.3909 - accuracy: 0.5106 - val_loss: 1.4038 - val_accuracy: 0.5024\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4038 - accuracy: 0.5024\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 25s 11ms/step - loss: 1.9534 - accuracy: 0.3018 - val_loss: 1.7248 - val_accuracy: 0.3905\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7414 - accuracy: 0.3743 - val_loss: 1.6311 - val_accuracy: 0.4215\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6607 - accuracy: 0.4071 - val_loss: 1.5501 - val_accuracy: 0.4478\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6024 - accuracy: 0.4295 - val_loss: 1.5383 - val_accuracy: 0.4487\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5531 - accuracy: 0.4453 - val_loss: 1.5278 - val_accuracy: 0.4557\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5165 - accuracy: 0.4612 - val_loss: 1.5007 - val_accuracy: 0.4702\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4826 - accuracy: 0.4737 - val_loss: 1.4699 - val_accuracy: 0.4744\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4507 - accuracy: 0.4868 - val_loss: 1.4443 - val_accuracy: 0.4910\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4179 - accuracy: 0.4989 - val_loss: 1.4355 - val_accuracy: 0.4894\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.3801 - accuracy: 0.5117 - val_loss: 1.4358 - val_accuracy: 0.4912\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4358 - accuracy: 0.4912\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 25s 11ms/step - loss: 1.9194 - accuracy: 0.3088 - val_loss: 1.7485 - val_accuracy: 0.3743\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7365 - accuracy: 0.3770 - val_loss: 1.6279 - val_accuracy: 0.4187\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6635 - accuracy: 0.4065 - val_loss: 1.6155 - val_accuracy: 0.4342\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6158 - accuracy: 0.4289 - val_loss: 1.5494 - val_accuracy: 0.4602\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5696 - accuracy: 0.4442 - val_loss: 1.5214 - val_accuracy: 0.4696\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5322 - accuracy: 0.4545 - val_loss: 1.4937 - val_accuracy: 0.4691\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4960 - accuracy: 0.4668 - val_loss: 1.4974 - val_accuracy: 0.4747\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4683 - accuracy: 0.4789 - val_loss: 1.4665 - val_accuracy: 0.4903\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4327 - accuracy: 0.4943 - val_loss: 1.4693 - val_accuracy: 0.4783\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4011 - accuracy: 0.5064 - val_loss: 1.4112 - val_accuracy: 0.5026\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4112 - accuracy: 0.5026\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 26s 12ms/step - loss: 1.9495 - accuracy: 0.2981 - val_loss: 1.8446 - val_accuracy: 0.3540\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7763 - accuracy: 0.3717 - val_loss: 1.7932 - val_accuracy: 0.3819\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7137 - accuracy: 0.3934 - val_loss: 1.6878 - val_accuracy: 0.4090\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6497 - accuracy: 0.4166 - val_loss: 1.7435 - val_accuracy: 0.3908\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6073 - accuracy: 0.4321 - val_loss: 1.6272 - val_accuracy: 0.4125\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5671 - accuracy: 0.4466 - val_loss: 1.5529 - val_accuracy: 0.4664\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5320 - accuracy: 0.4602 - val_loss: 1.5032 - val_accuracy: 0.4668\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4931 - accuracy: 0.4755 - val_loss: 1.5631 - val_accuracy: 0.4516\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4750 - accuracy: 0.4802 - val_loss: 1.5085 - val_accuracy: 0.4826\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4421 - accuracy: 0.4927 - val_loss: 1.5306 - val_accuracy: 0.4749\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5306 - accuracy: 0.4749\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 26s 12ms/step - loss: 1.9764 - accuracy: 0.2795 - val_loss: 1.9159 - val_accuracy: 0.3169\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7986 - accuracy: 0.3530 - val_loss: 1.7709 - val_accuracy: 0.3700\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7291 - accuracy: 0.3829 - val_loss: 1.8089 - val_accuracy: 0.3775\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6857 - accuracy: 0.4012 - val_loss: 1.8415 - val_accuracy: 0.3798\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6499 - accuracy: 0.4157 - val_loss: 1.6410 - val_accuracy: 0.4332\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6113 - accuracy: 0.4267 - val_loss: 1.5899 - val_accuracy: 0.4410\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5716 - accuracy: 0.4470 - val_loss: 1.6867 - val_accuracy: 0.4173\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5424 - accuracy: 0.4573 - val_loss: 1.6879 - val_accuracy: 0.4336\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5028 - accuracy: 0.4714 - val_loss: 1.5214 - val_accuracy: 0.4723\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4814 - accuracy: 0.4811 - val_loss: 1.6446 - val_accuracy: 0.4474\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6446 - accuracy: 0.4474\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 25s 11ms/step - loss: 2.0169 - accuracy: 0.2470 - val_loss: 1.9524 - val_accuracy: 0.2849\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.8663 - accuracy: 0.3108 - val_loss: 1.9904 - val_accuracy: 0.3220\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.8324 - accuracy: 0.3274 - val_loss: 2.0867 - val_accuracy: 0.2976\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.7851 - accuracy: 0.3422 - val_loss: 2.6039 - val_accuracy: 0.2767\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7595 - accuracy: 0.3577 - val_loss: 2.0973 - val_accuracy: 0.3360\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6995 - accuracy: 0.3835 - val_loss: 1.8858 - val_accuracy: 0.3496\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6590 - accuracy: 0.3977 - val_loss: 2.3055 - val_accuracy: 0.3044\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6144 - accuracy: 0.4163 - val_loss: 1.8632 - val_accuracy: 0.3621\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5928 - accuracy: 0.4274 - val_loss: 2.3720 - val_accuracy: 0.3023\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5515 - accuracy: 0.4461 - val_loss: 2142959168389120.0000 - val_accuracy: 0.3349\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2142959168389120.0000 - accuracy: 0.3349\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 25s 11ms/step - loss: 2.1235 - accuracy: 0.1824 - val_loss: 2.4692 - val_accuracy: 0.1957\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.0361 - accuracy: 0.2057 - val_loss: 7.6274 - val_accuracy: 0.1127\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.0093 - accuracy: 0.2159 - val_loss: 2803322368.0000 - val_accuracy: 0.1116\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9883 - accuracy: 0.2246 - val_loss: 10379006960237113507840.0000 - val_accuracy: 0.0943\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9674 - accuracy: 0.2359 - val_loss: 192433029455619750363136.0000 - val_accuracy: 0.1686\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9515 - accuracy: 0.2465 - val_loss: 5733203670631001278644224.0000 - val_accuracy: 0.1913\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9321 - accuracy: 0.2541 - val_loss: 8118836918414021289312256.0000 - val_accuracy: 0.1852\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9220 - accuracy: 0.2596 - val_loss: nan - val_accuracy: 0.1303\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9095 - accuracy: 0.2609 - val_loss: 3024552875191589422682408484864.0000 - val_accuracy: 0.1865\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9144 - accuracy: 0.2637 - val_loss: 1.9795 - val_accuracy: 0.2437\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.9795 - accuracy: 0.2437\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 27s 12ms/step - loss: 2.1567 - accuracy: 0.1720 - val_loss: 313008416.0000 - val_accuracy: 0.1825\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.0604 - accuracy: 0.1965 - val_loss: 67861118931959808.0000 - val_accuracy: 0.1623\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.0452 - accuracy: 0.1890 - val_loss: 24709791989102643511296.0000 - val_accuracy: 0.1965\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.0053 - accuracy: 0.2076 - val_loss: 4631871714907215888384.0000 - val_accuracy: 0.1671\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.0054 - accuracy: 0.2294 - val_loss: 701400739065842630656.0000 - val_accuracy: 0.1272\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9934 - accuracy: 0.2274 - val_loss: 3037868486295552.0000 - val_accuracy: 0.1561\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9804 - accuracy: 0.2362 - val_loss: 15093182521284478631936.0000 - val_accuracy: 0.1691\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9586 - accuracy: 0.2469 - val_loss: 72563208077367917994387177472.0000 - val_accuracy: 0.2126\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9640 - accuracy: 0.2457 - val_loss: 798035391064005672960.0000 - val_accuracy: 0.1616\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9570 - accuracy: 0.2514 - val_loss: 12271028654833664.0000 - val_accuracy: 0.2479\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 12271028654833664.0000 - accuracy: 0.2479\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 26s 12ms/step - loss: 2.1862 - accuracy: 0.1628 - val_loss: 6.0355 - val_accuracy: 0.1071\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.0986 - accuracy: 0.1952 - val_loss: 52822053496683696750592.0000 - val_accuracy: 0.1013\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.0752 - accuracy: 0.2027 - val_loss: 16397493841322929976041237643264.0000 - val_accuracy: 0.1617\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.0585 - accuracy: 0.2123 - val_loss: 23655170733706397446307840.0000 - val_accuracy: 0.1122\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.0520 - accuracy: 0.2172 - val_loss: 11973065917771490507822400012288.0000 - val_accuracy: 0.0818\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.0145 - accuracy: 0.2263 - val_loss: 2154143626779373134948597760.0000 - val_accuracy: 0.1911\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.0064 - accuracy: 0.2376 - val_loss: 92898676793000632822540533760.0000 - val_accuracy: 0.1155\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.0087 - accuracy: 0.2334 - val_loss: nan - val_accuracy: 0.1831\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9904 - accuracy: 0.2412 - val_loss: nan - val_accuracy: 0.2613\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9898 - accuracy: 0.2442 - val_loss: nan - val_accuracy: 0.1386\n",
      "313/313 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.1386\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 25s 11ms/step - loss: 4.3253 - accuracy: 0.1255 - val_loss: 90078590901722012698634002366464.0000 - val_accuracy: 0.1025\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.3565 - accuracy: 0.1269 - val_loss: nan - val_accuracy: 0.1627\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.3171 - accuracy: 0.1445 - val_loss: nan - val_accuracy: 0.1539\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 6.5520 - accuracy: 0.1533 - val_loss: nan - val_accuracy: 0.1339\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.1280 - accuracy: 0.1716 - val_loss: nan - val_accuracy: 0.1766\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.1477 - accuracy: 0.1715 - val_loss: nan - val_accuracy: 0.1630\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 6.6588 - accuracy: 0.1477 - val_loss: nan - val_accuracy: 0.1014\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.2811 - accuracy: 0.1428 - val_loss: nan - val_accuracy: 0.1468\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.1660 - accuracy: 0.1689 - val_loss: nan - val_accuracy: 0.1609\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.2153 - accuracy: 0.1672 - val_loss: nan - val_accuracy: 0.1393\n",
      "313/313 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.1393                \n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 25s 11ms/step - loss: 11.2333 - accuracy: 0.1316 - val_loss: 535349142955900310954939391148032.0000 - val_accuracy: 0.1175\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.2891 - accuracy: 0.1491 - val_loss: nan - val_accuracy: 0.1431\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 11.4332 - accuracy: 0.1441 - val_loss: nan - val_accuracy: 0.1031\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.2475 - accuracy: 0.1546 - val_loss: nan - val_accuracy: 0.1625\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 2.2256 - accuracy: 0.1667 - val_loss: nan - val_accuracy: 0.1568\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 13.6525 - accuracy: 0.1548 - val_loss: nan - val_accuracy: 0.1743\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.1925 - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1353\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.2511 - accuracy: 0.1761 - val_loss: nan - val_accuracy: 0.1692\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 18.5625 - accuracy: 0.1544 - val_loss: nan - val_accuracy: 0.1674\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.1502 - accuracy: 0.1682 - val_loss: nan - val_accuracy: 0.1599\n",
      "313/313 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.1599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[32,32,3]),\n",
    "])\n",
    "\n",
    "for i in range(20):\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
    "\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_normal\"))\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=10)\n",
    "\n",
    "\n",
    "find_optimal_lr(model, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1250/1250 [==============================] - 27s 11ms/step - loss: 1.8846 - accuracy: 0.3239 - val_loss: 1.7553 - val_accuracy: 0.3762\n",
      "Epoch 2/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7267 - accuracy: 0.3835 - val_loss: 1.6815 - val_accuracy: 0.4064\n",
      "Epoch 3/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6576 - accuracy: 0.4109 - val_loss: 1.5881 - val_accuracy: 0.4300\n",
      "Epoch 4/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6059 - accuracy: 0.4282 - val_loss: 1.5361 - val_accuracy: 0.4576\n",
      "Epoch 5/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5612 - accuracy: 0.4467 - val_loss: 1.4918 - val_accuracy: 0.4728\n",
      "Epoch 6/300\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.5186 - accuracy: 0.4610 - val_loss: 1.5042 - val_accuracy: 0.4619\n",
      "Epoch 7/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4877 - accuracy: 0.4757 - val_loss: 1.4676 - val_accuracy: 0.4686\n",
      "Epoch 8/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4580 - accuracy: 0.4825 - val_loss: 1.4669 - val_accuracy: 0.4808\n",
      "Epoch 9/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4274 - accuracy: 0.4964 - val_loss: 1.4234 - val_accuracy: 0.4976\n",
      "Epoch 10/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.3979 - accuracy: 0.5046 - val_loss: 1.4032 - val_accuracy: 0.5014\n",
      "Epoch 11/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.3693 - accuracy: 0.5182 - val_loss: 1.4370 - val_accuracy: 0.4894\n",
      "Epoch 12/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.3465 - accuracy: 0.5290 - val_loss: 1.4262 - val_accuracy: 0.5043\n",
      "Epoch 13/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.3247 - accuracy: 0.5312 - val_loss: 1.4341 - val_accuracy: 0.4994\n",
      "Epoch 14/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.3094 - accuracy: 0.5404 - val_loss: 1.4017 - val_accuracy: 0.5132\n",
      "Epoch 15/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.2821 - accuracy: 0.5499 - val_loss: 1.3923 - val_accuracy: 0.5131\n",
      "Epoch 16/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.2675 - accuracy: 0.5548 - val_loss: 1.3969 - val_accuracy: 0.5192\n",
      "Epoch 17/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.2524 - accuracy: 0.5614 - val_loss: 1.4170 - val_accuracy: 0.5149\n",
      "Epoch 18/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.2336 - accuracy: 0.5661 - val_loss: 1.3969 - val_accuracy: 0.5168\n",
      "Epoch 19/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.2178 - accuracy: 0.5735 - val_loss: 1.4042 - val_accuracy: 0.5217\n",
      "Epoch 20/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.2032 - accuracy: 0.5796 - val_loss: 1.4108 - val_accuracy: 0.5118\n",
      "Epoch 21/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.1886 - accuracy: 0.5844 - val_loss: 1.3889 - val_accuracy: 0.5205\n",
      "Epoch 22/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.1668 - accuracy: 0.5919 - val_loss: 1.3724 - val_accuracy: 0.5252\n",
      "Epoch 23/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.1573 - accuracy: 0.5954 - val_loss: 1.3972 - val_accuracy: 0.5175\n",
      "Epoch 24/300\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.1421 - accuracy: 0.6012 - val_loss: 1.4079 - val_accuracy: 0.5186\n",
      "Epoch 25/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.1395 - accuracy: 0.6029 - val_loss: 1.4196 - val_accuracy: 0.5087\n",
      "Epoch 26/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.1163 - accuracy: 0.6100 - val_loss: 1.4013 - val_accuracy: 0.5256\n",
      "Epoch 27/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.1129 - accuracy: 0.6105 - val_loss: 1.4049 - val_accuracy: 0.5265\n",
      "Epoch 28/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.1011 - accuracy: 0.6158 - val_loss: 1.3851 - val_accuracy: 0.5282\n",
      "Epoch 29/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.0837 - accuracy: 0.6227 - val_loss: 1.4429 - val_accuracy: 0.5175\n",
      "Epoch 30/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.0750 - accuracy: 0.6241 - val_loss: 1.3905 - val_accuracy: 0.5303\n",
      "Epoch 31/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.0613 - accuracy: 0.6307 - val_loss: 1.3869 - val_accuracy: 0.5302\n",
      "Epoch 32/300\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.0560 - accuracy: 0.6319 - val_loss: 1.4067 - val_accuracy: 0.5239\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5256"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.001),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=300, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "accuracy_score(y_test, np.argmax(model.predict(X_test), axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-normalizing Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1250/1250 [==============================] - 12s 5ms/step - loss: 1.9479 - accuracy: 0.2890 - val_loss: 1.8748 - val_accuracy: 0.3192\n",
      "Epoch 2/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.7511 - accuracy: 0.3696 - val_loss: 1.7307 - val_accuracy: 0.3543\n",
      "Epoch 3/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6669 - accuracy: 0.4064 - val_loss: 1.6934 - val_accuracy: 0.4029\n",
      "Epoch 4/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6123 - accuracy: 0.4267 - val_loss: 1.6808 - val_accuracy: 0.4144\n",
      "Epoch 5/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.5566 - accuracy: 0.4474 - val_loss: 1.6141 - val_accuracy: 0.4330\n",
      "Epoch 6/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.5155 - accuracy: 0.4636 - val_loss: 1.6207 - val_accuracy: 0.4234\n",
      "Epoch 7/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4737 - accuracy: 0.4788 - val_loss: 1.5596 - val_accuracy: 0.4509\n",
      "Epoch 8/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4409 - accuracy: 0.4902 - val_loss: 1.5594 - val_accuracy: 0.4550\n",
      "Epoch 9/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4155 - accuracy: 0.5006 - val_loss: 1.5446 - val_accuracy: 0.4500\n",
      "Epoch 10/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3714 - accuracy: 0.5161 - val_loss: 1.5584 - val_accuracy: 0.4645\n",
      "Epoch 11/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.3401 - accuracy: 0.5316 - val_loss: 1.5254 - val_accuracy: 0.4767\n",
      "Epoch 12/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3507 - accuracy: 0.5228 - val_loss: 1.5445 - val_accuracy: 0.4705\n",
      "Epoch 13/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.2922 - accuracy: 0.5461 - val_loss: 1.5283 - val_accuracy: 0.4805\n",
      "Epoch 14/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.2807 - accuracy: 0.5484 - val_loss: 1.5268 - val_accuracy: 0.4766\n",
      "Epoch 15/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.2612 - accuracy: 0.5566 - val_loss: 1.5295 - val_accuracy: 0.4739\n",
      "Epoch 16/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.2322 - accuracy: 0.5666 - val_loss: 1.5181 - val_accuracy: 0.4890\n",
      "Epoch 17/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1905 - accuracy: 0.5839 - val_loss: 1.5130 - val_accuracy: 0.4887\n",
      "Epoch 18/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1743 - accuracy: 0.5922 - val_loss: 1.5428 - val_accuracy: 0.4948\n",
      "Epoch 19/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 6.7707 - accuracy: 0.5841 - val_loss: 1.8066 - val_accuracy: 0.3780\n",
      "Epoch 20/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.4617 - accuracy: 0.4781 - val_loss: 1.5783 - val_accuracy: 0.4634\n",
      "Epoch 21/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3302 - accuracy: 0.5282 - val_loss: 1.5613 - val_accuracy: 0.4690\n",
      "Epoch 22/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.2802 - accuracy: 0.5476 - val_loss: 1.5526 - val_accuracy: 0.4675\n",
      "Epoch 23/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.2502 - accuracy: 0.5596 - val_loss: 1.5514 - val_accuracy: 0.4646\n",
      "Epoch 24/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.2252 - accuracy: 0.5666 - val_loss: 1.5643 - val_accuracy: 0.4809\n",
      "Epoch 25/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.2006 - accuracy: 0.5787 - val_loss: 1.5582 - val_accuracy: 0.4855\n",
      "Epoch 26/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1810 - accuracy: 0.5871 - val_loss: 1.5201 - val_accuracy: 0.4847\n",
      "Epoch 27/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.2015 - accuracy: 0.5787 - val_loss: 1.5618 - val_accuracy: 0.4672\n",
      "Training took 179.54741390701383 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "X_val = scaler.fit_transform(X_val.reshape(X_val.shape[0], -1))\n",
    "X_test = scaler.fit_transform(X_test.reshape(X_test.shape[0], -1))\n",
    "\n",
    "model = keras.models.Sequential([])\n",
    "\n",
    "for i in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_normal\"))\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=10)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999), \n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "st = time.monotonic()\n",
    "model.fit(X_train, y_train, epochs=300, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "et = time.monotonic()\n",
    "\n",
    "print(f\"Training took {et-st} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4665"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy_score(y_test, np.argmax(model.predict(X_test), axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularizing with Alpha Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1250/1250 [==============================] - 12s 5ms/step - loss: 1.9167 - accuracy: 0.3183 - val_loss: 1.8205 - val_accuracy: 0.3753\n",
      "Epoch 2/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.6931 - accuracy: 0.3970 - val_loss: 1.7574 - val_accuracy: 0.4057\n",
      "Epoch 3/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.6076 - accuracy: 0.4331 - val_loss: 1.6905 - val_accuracy: 0.4194\n",
      "Epoch 4/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.5385 - accuracy: 0.4568 - val_loss: 1.6204 - val_accuracy: 0.4493\n",
      "Epoch 5/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.4813 - accuracy: 0.4794 - val_loss: 1.6080 - val_accuracy: 0.4580\n",
      "Epoch 6/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.4383 - accuracy: 0.4987 - val_loss: 1.6389 - val_accuracy: 0.4698\n",
      "Epoch 7/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.3944 - accuracy: 0.5151 - val_loss: 1.6661 - val_accuracy: 0.4853\n",
      "Epoch 8/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.3555 - accuracy: 0.5278 - val_loss: 1.6504 - val_accuracy: 0.4775\n",
      "Epoch 9/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.3112 - accuracy: 0.5445 - val_loss: 1.6496 - val_accuracy: 0.4814\n",
      "Epoch 10/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.2765 - accuracy: 0.5565 - val_loss: 1.5747 - val_accuracy: 0.4961\n",
      "Epoch 11/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.2454 - accuracy: 0.5663 - val_loss: 1.6183 - val_accuracy: 0.5035\n",
      "Epoch 12/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.2158 - accuracy: 0.5781 - val_loss: 1.7007 - val_accuracy: 0.5027\n",
      "Epoch 13/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1846 - accuracy: 0.5914 - val_loss: 1.6996 - val_accuracy: 0.4930\n",
      "Epoch 14/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1517 - accuracy: 0.6018 - val_loss: 1.6842 - val_accuracy: 0.4982\n",
      "Epoch 15/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1257 - accuracy: 0.6101 - val_loss: 1.7694 - val_accuracy: 0.4997\n",
      "Epoch 16/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1001 - accuracy: 0.6197 - val_loss: 1.7517 - val_accuracy: 0.4919\n",
      "Epoch 17/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.0814 - accuracy: 0.6278 - val_loss: 1.8522 - val_accuracy: 0.5054\n",
      "Epoch 18/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.0498 - accuracy: 0.6382 - val_loss: 1.7536 - val_accuracy: 0.4971\n",
      "Epoch 19/300\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.0365 - accuracy: 0.6454 - val_loss: 1.6871 - val_accuracy: 0.5048\n",
      "Epoch 20/300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.0077 - accuracy: 0.6522 - val_loss: 1.8853 - val_accuracy: 0.5031\n",
      "Training took 137.1549908129964 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "model = keras.models.Sequential([])\n",
    "\n",
    "for i in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.2))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_normal\"))\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=10)\n",
    "run_index = 1\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir=os.path.join(os.curdir, \"logs\", \"run_\" + str(run_index)))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Nadam(learning_rate=5e-4, beta_1=0.9, beta_2=0.999), \n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "st = time.monotonic()\n",
    "model.fit(X_train, y_train, epochs=300, validation_data=(X_val, y_val), callbacks=[early_stopping, tensorboard])\n",
    "et = time.monotonic()\n",
    "\n",
    "print(f\"Training took {et-st} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5019"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, np.argmax(model.predict(X_test), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test, training=True) for sample in range(500)])\n",
    "y_proba = y_probas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5022"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, np.argmax(y_proba, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        keras.backend.set_value(self.model.optimizer.learning_rate, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1250/1250 [==============================] - 7s 4ms/step - loss: 1.9646 - accuracy: 0.3063 - val_loss: 1.7703 - val_accuracy: 0.3950\n",
      "Epoch 2/15\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6820 - accuracy: 0.4010 - val_loss: 1.7144 - val_accuracy: 0.4164\n",
      "Epoch 3/15\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6092 - accuracy: 0.4292 - val_loss: 1.7010 - val_accuracy: 0.4210\n",
      "Epoch 4/15\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.5610 - accuracy: 0.4503 - val_loss: 1.7420 - val_accuracy: 0.4317\n",
      "Epoch 5/15\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.5265 - accuracy: 0.4608 - val_loss: 1.7159 - val_accuracy: 0.4207\n",
      "Epoch 6/15\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4997 - accuracy: 0.4740 - val_loss: 1.8140 - val_accuracy: 0.4314\n",
      "Epoch 7/15\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4784 - accuracy: 0.4836 - val_loss: 1.7156 - val_accuracy: 0.4602\n",
      "Epoch 8/15\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4133 - accuracy: 0.5050 - val_loss: 1.6813 - val_accuracy: 0.4646\n",
      "Epoch 9/15\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3252 - accuracy: 0.5394 - val_loss: 1.6539 - val_accuracy: 0.4728\n",
      "Epoch 10/15\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.2456 - accuracy: 0.5622 - val_loss: 1.6247 - val_accuracy: 0.5097\n",
      "Epoch 11/15\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.1607 - accuracy: 0.5932 - val_loss: 1.6429 - val_accuracy: 0.5058\n",
      "Epoch 12/15\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.0746 - accuracy: 0.6240 - val_loss: 1.6975 - val_accuracy: 0.5097\n",
      "Epoch 13/15\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.9843 - accuracy: 0.6560 - val_loss: 1.7114 - val_accuracy: 0.5228\n",
      "Epoch 14/15\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.8894 - accuracy: 0.6883 - val_loss: 1.8187 - val_accuracy: 0.5260\n",
      "Epoch 15/15\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.8295 - accuracy: 0.7101 - val_loss: 1.8693 - val_accuracy: 0.5258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc2989f8f50>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "model = keras.models.Sequential([])\n",
    "for i in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.AlphaDropout(rate=0.2))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_normal\"))\n",
    "\n",
    "onecycle = OneCycleScheduler(math.ceil(len(X_train) / 32) * epochs, 0.05)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val), callbacks=[onecycle, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5312"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, np.argmax(model.predict(X_test), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
